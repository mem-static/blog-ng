{"componentChunkName":"component---src-templates-post-js","path":"/research/paper-reading/deepseek-math/","result":{"data":{"site":{"siteMetadata":{"title":"mem 的小站"}},"post":{"id":"a2126658-cc91-561a-9f63-df9dcd744e0b","excerpt":"1. Background 2. Method  PPO v.s. GRPO  一个显著的区别是 GRPO 放弃了价值模型（在 PPO 中，价值模型的参数量通常与策略模型相当），而是从组分数中估计 baseline，从而显著减少训练资源。  3. Experiments 使用 DeekSeek-Coder-Base-v…","html":"<h2 id=\"anchor-34a6bfca11a95d27\" style=\"position: relative;\"><a href=\"#anchor-34a6bfca11a95d27\" aria-label=\"anchor 34a6bfca11a95d27 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. Background</h2>\n<h2 id=\"anchor-8ee469971566a4f3\" style=\"position: relative;\"><a href=\"#anchor-8ee469971566a4f3\" aria-label=\"anchor 8ee469971566a4f3 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. Method</h2>\n<p><details open class=\"callout callout-type-important\"><summary style=\"pointer-events: none;\"> PPO v.s. GRPO</summary><div class=\"callout-content\"><p></p><p>一个显著的区别是 GRPO 放弃了价值模型（在 PPO 中，价值模型的参数量通常与策略模型相当），而是从组分数中估计 baseline，从而显著减少训练资源。</p><p><img src=\"https://img.memset0.cn/2025/03/27/0fCAv40j.png\"alt=\"\" style=\"width: 614px; \" ></p></div></details></p>\n<h2 id=\"anchor-6aa8924d279f3480\" style=\"position: relative;\"><a href=\"#anchor-6aa8924d279f3480\" aria-label=\"anchor 6aa8924d279f3480 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. Experiments</h2>\n<ul>\n<li>使用 DeekSeek-Coder-Base-v1.5 7B 作为基座模型，进行 Math Pre-Training 得到 DeepSeekMath-Base</li>\n<li>使用 chain-of-throught (CoT)、program-of-thought (PoT)、tool-integrated reasoning 数据对 DeepSeekMath-Base 进行数学指令微调，并最终得到 DeepSeekMath-Instruct-7B</li>\n</ul>\n<h2 id=\"anchor-438776c074c5f1a8\" style=\"position: relative;\"><a href=\"#anchor-438776c074c5f1a8\" aria-label=\"anchor 438776c074c5f1a8 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4. Code</h2>\n<h3 id=\"anchor-a1f3fa8166d228d6\" style=\"position: relative;\"><a href=\"#anchor-a1f3fa8166d228d6\" aria-label=\"anchor a1f3fa8166d228d6 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4.1. Computing KL Divergence</h3>\n<p><img src=\"https://img.memset0.cn/2025/03/28/0VewRVTS.png\"alt=\"\" ></p>\n<h2 id=\"anchor-b283d4aed4c4c7c4\" style=\"position: relative;\"><a href=\"#anchor-b283d4aed4c4c7c4\" aria-label=\"anchor b283d4aed4c4c7c4 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>5. References</h2>\n<ul>\n<li>原始论文</li>\n<li><a href=\"https://zhuanlan.zhihu.com/p/22051002772\">DeepSeekMath PPO 和 GRPO 原理 - 知乎</a></li>\n<li><a href=\"https://zhuanlan.zhihu.com/p/21178712267\">学习 deepseek R1：一文读懂大语言模型中的强化学习(SFT、RFT、DPO、PPO、GRPO) - 知乎</a></li>\n<li><a href=\"https://www.bilibili.com/video/BV1enQLYKEA5\">DeepSeek-GRPO_哔哩哔哩_bilibili</a></li>\n</ul>","tableOfContents":"<ul>\n<li>\n<p><a href=\"#anchor-34a6bfca11a95d27\">1. Background</a></p>\n</li>\n<li>\n<p><a href=\"#anchor-8ee469971566a4f3\">2. Method</a></p>\n</li>\n<li>\n<p><a href=\"#anchor-6aa8924d279f3480\">3. Experiments</a></p>\n</li>\n<li>\n<p><a href=\"#anchor-438776c074c5f1a8\">4. Code</a></p>\n<ul>\n<li><a href=\"#anchor-a1f3fa8166d228d6\">4.1. Computing KL Divergence</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#anchor-b283d4aed4c4c7c4\">5. References</a></p>\n</li>\n</ul>","frontmatter":{"title":"「论文精读 #22」DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models","description":null},"fields":{"cover":null,"slug":"/research/paper-reading/deepseek-math/","cssclasses":null,"isDoc":null,"authors":[],"createTime":"2025 年 3 月 25 日","updateTime":"2025 年 3 月 25 日","category":"[{\"name\":\"科研\",\"to\":\"/research/\"},{\"name\":\"论文精读\",\"to\":\"/research/paper-reading/\"}]","propsJson":null}},"previous":null,"next":null},"pageContext":{"id":"a2126658-cc91-561a-9f63-df9dcd744e0b","previousPostId":null,"nextPostId":null,"navJson":""}},"staticQueryHashes":["3871233186"],"slicesMap":{}}