{"componentChunkName":"component---src-templates-post-list-js","path":"/research/paper-reading/","result":{"data":{"posts":{"edges":[{"node":{"id":"e02b622c-9e23-5b41-a18b-aaaa974ec09b","excerptAst":{"type":"root","children":[{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"本篇笔记详细解析了强化学习中的 Proximal Policy Optimization (PPO) 算法，包括其理论基础、关键方法及优化策略。首先，介绍了强化学习的基本概念，如策略梯度方法及其目标函数推导。随后，探讨了 Actor-Critic 方法，并引入广义优势估计以优化策略更新的稳定性。接着，笔记重点介绍了 PPO 算法的核心思想，包括重要性采样、裁剪目标函数以及自适应 KL 惩罚，以确保策略更新的稳定性和高效性。最后，提供了相关参考资料及个人笔记，以便进一步学习和理解。 "},{"type":"element","tagName":"small","properties":{"style":"font-style: italic; opacity: 0.5"},"children":[{"type":"text","value":"（由 gpt-4o 生成摘要）"}]}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"}],"data":{"quirksMode":false}},"fields":{"slug":"/research/paper-reading/ppo/","category":"[{\"name\":\"科研\",\"to\":\"/research/\"},{\"name\":\"论文精读\",\"to\":\"/research/paper-reading/\"}]","publishedTitle":"「论文精读 #24」Proximal Policy Optimization Algorithms","createTime":"2025-03-25","cover":null}}},{"node":{"id":"d8e571fe-f435-5b2c-bbb8-60f61debcee9","excerptAst":{"type":"root","children":[{"type":"comment","value":" end-private-notes "},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"本篇笔记总结了一种基于文本的图像编辑方法，该方法利用扩散模型中的交叉注意力层来实现仅通过修改文本提示进行图像编辑。相比于传统的基于掩码的方法，该方法能够更自然地保留原始图像的结构，同时实现局部或全局的编辑。笔记详细介绍了该方法的核心思想，并列举了三种不同的编辑方式：单词替换、添加新短语以及注意力重新加权。通过这些方法，用户可以更精细地控制文本对图像生成的影响，从而实现高质量的编辑效果。 "},{"type":"element","tagName":"small","properties":{"style":"font-style: italic; opacity: 0.5"},"children":[{"type":"text","value":"（由 gpt-4o 生成摘要）"}]}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"}],"data":{"quirksMode":false}},"fields":{"slug":"/research/paper-reading/prompt-to-prompt/","category":"[{\"name\":\"科研\",\"to\":\"/research/\"},{\"name\":\"论文精读\",\"to\":\"/research/paper-reading/\"}]","publishedTitle":"「论文精读 #15」Prompt-to-Prompt Image Editing with Cross Attention Control","createTime":"2025-03-13","cover":null}}},{"node":{"id":"1274aa70-7836-513c-9be1-a1424c934fdf","excerptAst":{"type":"root","children":[{"type":"comment","value":" end-private-notes "},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"本篇笔记对论文 "},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"Denoising Diffusion Implicit Models (DDIM)"}]},{"type":"text","value":" 进行了深入解读，重点分析其相较于 DDPM 的改进之处。DDIM 通过放宽马尔科夫链假设，构造了一个非马尔科夫的随机过程，并利用设定的边际分布推导逆过程，使得在相同参数条件下仍可遵循高斯分布。该方法允许跳步采样，从而大幅减少生成步数，加速推理过程，同时保持图像质量。DDIM 的方法与 DDPM 兼容，因此可直接复用 DDPM 的训练模型。此外，笔记还探讨了损失函数的优化对模型效果的影响，并提供了详细的数学推导与直觉解释。"},{"type":"element","tagName":"small","properties":{"style":"font-style: italic; opacity: 0.5"},"children":[{"type":"text","value":"（由 gpt-4o 生成摘要）"}]}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"}],"data":{"quirksMode":false}},"fields":{"slug":"/research/paper-reading/ddim/","category":"[{\"name\":\"科研\",\"to\":\"/research/\"},{\"name\":\"论文精读\",\"to\":\"/research/paper-reading/\"}]","publishedTitle":"「论文精读 #9」Denoising Diffusion Implicit Models","createTime":"2025-02-16","cover":null}}},{"node":{"id":"9a3ddd65-a1fd-5ee3-be7c-ff94457ad762","excerptAst":{"type":"root","children":[{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"本篇笔记详细介绍了 ProNE 这一高效的网络表示学习方法。ProNE 主要包含两个关键步骤：基于稀疏矩阵分解的快速嵌入初始化，以及基于谱传播的嵌入增强。笔记重点阐述了谱传播部分的理论基础，包括调制网络的构建、带通滤波器的设计，以及如何通过切比雪夫多项式展开来提高计算效率。通过这种方法，ProNE 能够在保持高效计算的同时，同时捕获网络的局部结构信息和全局社区特征。"},{"type":"element","tagName":"small","properties":{"style":"font-style: italic; opacity: 0.5"},"children":[{"type":"text","value":"（由 claude-3.5-sonnet 生成摘要）"}]}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"}],"data":{"quirksMode":false}},"fields":{"slug":"/research/paper-reading/ProNE/","category":"[{\"name\":\"科研\",\"to\":\"/research/\"},{\"name\":\"论文精读\",\"to\":\"/research/paper-reading/\"}]","publishedTitle":"「论文精读 #5」ProNE: Fast and Scalable Network Representation Learning","createTime":"2025-02-04","cover":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/4b0b3d5015c5d89e76979d3eebc52122/0a8f2/U2xOTtuL.png","srcSet":"/static/4b0b3d5015c5d89e76979d3eebc52122/ca29c/U2xOTtuL.png 284w,\n/static/4b0b3d5015c5d89e76979d3eebc52122/dbb27/U2xOTtuL.png 569w,\n/static/4b0b3d5015c5d89e76979d3eebc52122/0a8f2/U2xOTtuL.png 1137w","sizes":"(min-width: 1137px) 1137px, 100vw"},"sources":[{"srcSet":"/static/4b0b3d5015c5d89e76979d3eebc52122/fff99/U2xOTtuL.webp 284w,\n/static/4b0b3d5015c5d89e76979d3eebc52122/a61a4/U2xOTtuL.webp 569w,\n/static/4b0b3d5015c5d89e76979d3eebc52122/1028a/U2xOTtuL.webp 1137w","type":"image/webp","sizes":"(min-width: 1137px) 1137px, 100vw"}]},"width":1137,"height":769}}}}}},{"node":{"id":"767861e1-782b-58ec-897c-531937c20dd5","excerptAst":{"type":"root","children":[{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"本篇笔记系统解析了 NetSMF 算法如何通过谱稀疏化与随机化矩阵分解技术，解决大规模网络嵌入中的计算瓶颈问题。核心创新在于将 NetMF 的稠密矩阵分解转化为稀疏矩阵分解，通过路径采样构建谱相似稀疏矩阵，结合随机化 SVD 实现高效低秩近似。实验部分对比了 LINE/DeepWalk/node2vec/NetMF 等主流方法，验证了 NetSMF 在保持多跳依赖建模能力的同时显著提升计算效率，参数分析揭示了样本数量与嵌入维度的边际效益特性。"},{"type":"element","tagName":"small","properties":{"style":"font-style: italic; opacity: 0.5"},"children":[{"type":"text","value":"（由 deepseek-r1 生成摘要）"}]}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"}],"data":{"quirksMode":false}},"fields":{"slug":"/research/paper-reading/netsmf/","category":"[{\"name\":\"科研\",\"to\":\"/research/\"},{\"name\":\"论文精读\",\"to\":\"/research/paper-reading/\"}]","publishedTitle":"「论文精读 #4」NetSMF: Large-Scale Network Embedding as Sparse Matrix Factorization","createTime":"2025-01-30","cover":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/22765464909ec562283e63ca33051977/e696e/nYD7xfTJ.png","srcSet":"/static/22765464909ec562283e63ca33051977/28390/nYD7xfTJ.png 365w,\n/static/22765464909ec562283e63ca33051977/b3e78/nYD7xfTJ.png 730w,\n/static/22765464909ec562283e63ca33051977/e696e/nYD7xfTJ.png 1459w","sizes":"(min-width: 1459px) 1459px, 100vw"},"sources":[{"srcSet":"/static/22765464909ec562283e63ca33051977/e69e7/nYD7xfTJ.webp 365w,\n/static/22765464909ec562283e63ca33051977/c4b80/nYD7xfTJ.webp 730w,\n/static/22765464909ec562283e63ca33051977/91ef9/nYD7xfTJ.webp 1459w","type":"image/webp","sizes":"(min-width: 1459px) 1459px, 100vw"}]},"width":1459,"height":696}}}}}},{"node":{"id":"3e2307f9-b386-5d30-b791-1a5bfdaf8ce0","excerptAst":{"type":"root","children":[{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"本篇笔记系统分析了 NetMF 论文的核心贡献：通过理论推导证明 DeepWalk、LINE 等图嵌入算法本质是隐式矩阵分解，并提出了显式的矩阵分解框架 NetMF。笔记详细推导了基于随机游走的 PMI 矩阵闭式解 "},{"type":"element","tagName":"span","properties":{"className":["math","math-inline"]},"children":[{"type":"element","tagName":"span","properties":{"className":["katex"]},"children":[{"type":"element","tagName":"span","properties":{"className":["katex-mathml"]},"children":[{"type":"element","tagName":"math","properties":{"xmlns":"http://www.w3.org/1998/Math/MathML"},"children":[{"type":"element","tagName":"semantics","properties":{},"children":[{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"mstyle","properties":{"scriptlevel":"0","displaystyle":"true"},"children":[{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"mi","properties":{"mathvariant":"bold"},"children":[{"type":"text","value":"M"}]},{"type":"element","tagName":"mo","properties":{},"children":[{"type":"text","value":"="}]},{"type":"element","tagName":"mtext","properties":{},"children":[{"type":"text","value":"vol"}]},{"type":"element","tagName":"mo","properties":{"stretchy":"false"},"children":[{"type":"text","value":"("}]},{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"G"}]},{"type":"element","tagName":"mo","properties":{"stretchy":"false"},"children":[{"type":"text","value":")"}]},{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"mo","properties":{"fence":"true"},"children":[{"type":"text","value":"("}]},{"type":"element","tagName":"mfrac","properties":{},"children":[{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"1"}]},{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"T"}]}]},{"type":"element","tagName":"munderover","properties":{},"children":[{"type":"element","tagName":"mo","properties":{},"children":[{"type":"text","value":"∑"}]},{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"r"}]},{"type":"element","tagName":"mo","properties":{},"children":[{"type":"text","value":"="}]},{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"1"}]}]},{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"T"}]}]},{"type":"element","tagName":"msup","properties":{},"children":[{"type":"element","tagName":"mi","properties":{"mathvariant":"bold"},"children":[{"type":"text","value":"P"}]},{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"r"}]}]},{"type":"element","tagName":"mo","properties":{"fence":"true"},"children":[{"type":"text","value":")"}]}]},{"type":"element","tagName":"msup","properties":{},"children":[{"type":"element","tagName":"mi","properties":{"mathvariant":"bold"},"children":[{"type":"text","value":"D"}]},{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"mo","properties":{},"children":[{"type":"text","value":"−"}]},{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"1"}]}]}]}]}]}]},{"type":"element","tagName":"annotation","properties":{"encoding":"application/x-tex"},"children":[{"type":"text","value":"\\displaystyle{\\mathbf{M} = \\text{vol}(G)\\left(\\frac{1}{T}\\sum_{r=1}^T \\mathbf{P}^r\\right)\\mathbf{D}^{-1}}"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["katex-html"],"ariaHidden":"true"},"children":[{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:3.0954em;vertical-align:-1.2671em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathbf"]},"children":[{"type":"text","value":"M"}]},{"type":"element","tagName":"span","properties":{"className":["mspace"],"style":"margin-right:0.2778em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mrel"]},"children":[{"type":"text","value":"="}]},{"type":"element","tagName":"span","properties":{"className":["mspace"],"style":"margin-right:0.2778em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord","text"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"text","value":"vol"}]}]},{"type":"element","tagName":"span","properties":{"className":["mopen"]},"children":[{"type":"text","value":"("}]},{"type":"element","tagName":"span","properties":{"className":["mord","mathnormal"]},"children":[{"type":"text","value":"G"}]},{"type":"element","tagName":"span","properties":{"className":["mclose"]},"children":[{"type":"text","value":")"}]},{"type":"element","tagName":"span","properties":{"className":["mspace"],"style":"margin-right:0.1667em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["minner"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mopen","delimcenter"],"style":"top:0em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["delimsizing","size4"]},"children":[{"type":"text","value":"("}]}]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mopen","nulldelimiter"]},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mfrac"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t","vlist-t2"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:1.3214em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-2.314em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:3em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathnormal"],"style":"margin-right:0.13889em;"},"children":[{"type":"text","value":"T"}]}]}]},{"type":"element","tagName":"span","properties":{"style":"top:-3.23em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:3em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["frac-line"],"style":"border-bottom-width:0.04em;"},"children":[]}]},{"type":"element","tagName":"span","properties":{"style":"top:-3.677em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:3em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"text","value":"1"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-s"]},"children":[{"type":"text","value":"​"}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.686em;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["mclose","nulldelimiter"]},"children":[]}]},{"type":"element","tagName":"span","properties":{"className":["mspace"],"style":"margin-right:0.1667em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mop","op-limits"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t","vlist-t2"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:1.8283em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-1.8829em;margin-left:0em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:3.05em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathnormal","mtight"],"style":"margin-right:0.02778em;"},"children":[{"type":"text","value":"r"}]},{"type":"element","tagName":"span","properties":{"className":["mrel","mtight"]},"children":[{"type":"text","value":"="}]},{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"text","value":"1"}]}]}]}]},{"type":"element","tagName":"span","properties":{"style":"top:-3.05em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:3.05em;"},"children":[]},{"type":"element","tagName":"span","properties":{},"children":[{"type":"element","tagName":"span","properties":{"className":["mop","op-symbol","large-op"]},"children":[{"type":"text","value":"∑"}]}]}]},{"type":"element","tagName":"span","properties":{"style":"top:-4.3em;margin-left:0em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:3.05em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathnormal","mtight"],"style":"margin-right:0.13889em;"},"children":[{"type":"text","value":"T"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-s"]},"children":[{"type":"text","value":"​"}]}]},{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:1.2671em;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["mspace"],"style":"margin-right:0.1667em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathbf"]},"children":[{"type":"text","value":"P"}]},{"type":"element","tagName":"span","properties":{"className":["msupsub"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.7144em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-3.113em;margin-right:0.05em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:2.7em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathnormal","mtight"],"style":"margin-right:0.02778em;"},"children":[{"type":"text","value":"r"}]}]}]}]}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["mclose","delimcenter"],"style":"top:0em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["delimsizing","size4"]},"children":[{"type":"text","value":")"}]}]}]},{"type":"element","tagName":"span","properties":{"className":["mspace"],"style":"margin-right:0.1667em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mathbf"]},"children":[{"type":"text","value":"D"}]},{"type":"element","tagName":"span","properties":{"className":["msupsub"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-t"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist-r"]},"children":[{"type":"element","tagName":"span","properties":{"className":["vlist"],"style":"height:0.8641em;"},"children":[{"type":"element","tagName":"span","properties":{"style":"top:-3.113em;margin-right:0.05em;"},"children":[{"type":"element","tagName":"span","properties":{"className":["pstrut"],"style":"height:2.7em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["sizing","reset-size6","size3","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"text","value":"−"}]},{"type":"element","tagName":"span","properties":{"className":["mord","mtight"]},"children":[{"type":"text","value":"1"}]}]}]}]}]}]}]}]}]}]}]}]}]}]},{"type":"text","value":"，阐述了 NetMF 通过截断 SVD 分解该矩阵的实现方案，其中小窗口直接计算矩阵幂，大窗口采用特征值分解近似。笔记还记录了算法中 Shifted PPMI 处理、误差界理论证明等关键技术细节，最终通过矩阵分解视角统一了多种图嵌入方法。"},{"type":"element","tagName":"small","properties":{"style":"font-style: italic; opacity: 0.5"},"children":[{"type":"text","value":"（由 deepseek-r1 生成摘要）"}]}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"}],"data":{"quirksMode":false}},"fields":{"slug":"/research/paper-reading/netmf/","category":"[{\"name\":\"科研\",\"to\":\"/research/\"},{\"name\":\"论文精读\",\"to\":\"/research/paper-reading/\"}]","publishedTitle":"「论文精读 #3」Network Embedding as Matrix Factorization: Unifying DeepWalk, LINE, PTE, and node2vec","createTime":"2025-01-30","cover":null}}},{"node":{"id":"873d11d0-b83a-59ed-ba6d-d5d962a923ec","excerptAst":{"type":"root","children":[{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"本篇笔记系统剖析了 Skip-Gram with Negative Sampling (SGNS) 算法的核心原理及其与矩阵分解的深层联系。重点推导了 SGNS 目标函数与点互信息（PMI）的数学等价性，揭示了通过 Shifted PPMI 矩阵的 SVD 分解实现词向量生成的机制，并对比了 SGNS、SPPMI 和 SVD 方法在不同 NLP 任务中的性能差异。最后通过 DeepWalk 案例展示了该理论在图嵌入中的实际应用。"},{"type":"element","tagName":"small","properties":{"style":"font-style: italic; opacity: 0.5"},"children":[{"type":"text","value":"（由 deepseek-r1 生成摘要）"}]}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"}],"data":{"quirksMode":false}},"fields":{"slug":"/research/paper-reading/sgns/","category":"[{\"name\":\"科研\",\"to\":\"/research/\"},{\"name\":\"论文精读\",\"to\":\"/research/paper-reading/\"}]","publishedTitle":"「论文精读 #2」Neural Word Embedding as Implicit Matrix Factorization","createTime":"2025-01-27","cover":null}}},{"node":{"id":"85249dcd-0b94-56a5-8081-d0ffa2e4f747","excerptAst":{"type":"root","children":[{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"本篇笔记系统解析了 DeepWalk 算法在图表征学习中的应用，重点阐述了其通过随机游走生成节点序列并运用 Skip-Gram 模型进行嵌入学习的核心机制。笔记深入探讨了幂律分布在无标度图与自然语言处理中的相似性，揭示了层次化 Softmax 如何通过霍夫曼树编码将计算复杂度从 "},{"type":"element","tagName":"span","properties":{"className":["math","math-inline"]},"children":[{"type":"element","tagName":"span","properties":{"className":["katex"]},"children":[{"type":"element","tagName":"span","properties":{"className":["katex-mathml"]},"children":[{"type":"element","tagName":"math","properties":{"xmlns":"http://www.w3.org/1998/Math/MathML"},"children":[{"type":"element","tagName":"semantics","properties":{},"children":[{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"O"}]},{"type":"element","tagName":"mo","properties":{"stretchy":"false"},"children":[{"type":"text","value":"("}]},{"type":"element","tagName":"mi","properties":{"mathvariant":"normal"},"children":[{"type":"text","value":"∣"}]},{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"V"}]},{"type":"element","tagName":"mi","properties":{"mathvariant":"normal"},"children":[{"type":"text","value":"∣"}]},{"type":"element","tagName":"mo","properties":{"stretchy":"false"},"children":[{"type":"text","value":")"}]}]},{"type":"element","tagName":"annotation","properties":{"encoding":"application/x-tex"},"children":[{"type":"text","value":"O(|V|)"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["katex-html"],"ariaHidden":"true"},"children":[{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:1em;vertical-align:-0.25em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord","mathnormal"],"style":"margin-right:0.02778em;"},"children":[{"type":"text","value":"O"}]},{"type":"element","tagName":"span","properties":{"className":["mopen"]},"children":[{"type":"text","value":"("}]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"text","value":"∣"}]},{"type":"element","tagName":"span","properties":{"className":["mord","mathnormal"],"style":"margin-right:0.22222em;"},"children":[{"type":"text","value":"V"}]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"text","value":"∣"}]},{"type":"element","tagName":"span","properties":{"className":["mclose"]},"children":[{"type":"text","value":")"}]}]}]}]}]},{"type":"text","value":" 降至 "},{"type":"element","tagName":"span","properties":{"className":["math","math-inline"]},"children":[{"type":"element","tagName":"span","properties":{"className":["katex"]},"children":[{"type":"element","tagName":"span","properties":{"className":["katex-mathml"]},"children":[{"type":"element","tagName":"math","properties":{"xmlns":"http://www.w3.org/1998/Math/MathML"},"children":[{"type":"element","tagName":"semantics","properties":{},"children":[{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"O"}]},{"type":"element","tagName":"mo","properties":{"stretchy":"false"},"children":[{"type":"text","value":"("}]},{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"log"}]},{"type":"element","tagName":"mo","properties":{},"children":[{"type":"text","value":"⁡"}]},{"type":"element","tagName":"mi","properties":{"mathvariant":"normal"},"children":[{"type":"text","value":"∣"}]},{"type":"element","tagName":"mi","properties":{},"children":[{"type":"text","value":"V"}]},{"type":"element","tagName":"mi","properties":{"mathvariant":"normal"},"children":[{"type":"text","value":"∣"}]},{"type":"element","tagName":"mo","properties":{"stretchy":"false"},"children":[{"type":"text","value":")"}]}]},{"type":"element","tagName":"annotation","properties":{"encoding":"application/x-tex"},"children":[{"type":"text","value":"O(\\log |V|)"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["katex-html"],"ariaHidden":"true"},"children":[{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:1em;vertical-align:-0.25em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord","mathnormal"],"style":"margin-right:0.02778em;"},"children":[{"type":"text","value":"O"}]},{"type":"element","tagName":"span","properties":{"className":["mopen"]},"children":[{"type":"text","value":"("}]},{"type":"element","tagName":"span","properties":{"className":["mop"]},"children":[{"type":"text","value":"lo"},{"type":"element","tagName":"span","properties":{"style":"margin-right:0.01389em;"},"children":[{"type":"text","value":"g"}]}]},{"type":"element","tagName":"span","properties":{"className":["mspace"],"style":"margin-right:0.1667em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"text","value":"∣"}]},{"type":"element","tagName":"span","properties":{"className":["mord","mathnormal"],"style":"margin-right:0.22222em;"},"children":[{"type":"text","value":"V"}]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"text","value":"∣"}]},{"type":"element","tagName":"span","properties":{"className":["mclose"]},"children":[{"type":"text","value":")"}]}]}]}]}]},{"type":"text","value":"，并通过代码实例对比了传统 Softmax 与层次化实现的差异。实验部分展示了嵌入维度、游走次数等参数对模型性能的影响曲线，最后指出该方法仅利用图结构信息而忽略节点属性的特点。"},{"type":"element","tagName":"small","properties":{"style":"font-style: italic; opacity: 0.5"},"children":[{"type":"text","value":"（由 deepseek-r1 生成摘要）"}]}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"}],"data":{"quirksMode":false}},"fields":{"slug":"/research/paper-reading/deepwalk/","category":"[{\"name\":\"科研\",\"to\":\"/research/\"},{\"name\":\"论文精读\",\"to\":\"/research/paper-reading/\"}]","publishedTitle":"「论文精读 #1」DeepWalk: Online Learning of Social Representations","createTime":"2025-01-25","cover":null}}}]}},"pageContext":{"pathPrefix":"/research/paper-reading/","publishStatus":[true,false],"prefixRegex":"^/research/paper-reading/","names":"[\"科研\",\"论文精读\"]","format":"index","pageNumber":0,"humanPageNumber":1,"skip":0,"limit":10,"numberOfPages":1,"previousPagePath":"","nextPagePath":""}},"staticQueryHashes":["3871233186"],"slicesMap":{}}